Device: Tesla P40
Compute capability: 6.1
Clock rate: 1.53 GHz
Number of SMs: 30

===== Low-Latency GPU Packet Processing =====
Testing with 10000 packets


=== Stage 0: CPU-based Processing (Baseline) ===
Batch size: 10000 packets
Total time: 4379 us
Average latency per packet: 0.00 us
Processed 10000 packets: 1448 drops, 1573 forwards, 6979 modifies
CPU processing (total): 4379 us

=== Stage 1: Basic Packet Processing ===
Kernel execution time: 674 us
Batch size: 10000 packets
Total time: 4214 us
Kernel time: 674 us (16.0%)
Average latency per packet: 0.00 us
Processed 10000 packets: 1448 drops, 1573 forwards, 6979 modifies
Basic processing (total): 4214 us

=== Batch Size Exploration ===

--- Testing Batch Size = 32 ---
Batch size 32: total=127704 us, transfer=4109 us, kernel=121134 us
Average latency per batch: 408.00 us, per packet: 12.77 us
Batch size: 32 packets
Total time: 127704 us
Transfer time: 4109 us (3.2%)
Kernel time: 121134 us (94.9%)
Average latency per batch: 408.00 us
Average latency per packet: 12.77 us
Processed 10000 packets: 1448 drops, 1573 forwards, 6979 modifies

--- Testing Batch Size = 64 ---
Batch size 64: total=67056 us, transfer=3242 us, kernel=62513 us
Average latency per batch: 427.11 us, per packet: 6.71 us
Batch size: 64 packets
Total time: 67056 us
Transfer time: 3242 us (4.8%)
Kernel time: 62513 us (93.2%)
Average latency per batch: 427.11 us
Average latency per packet: 6.71 us
Processed 10000 packets: 1448 drops, 1573 forwards, 6979 modifies

--- Testing Batch Size = 128 ---
Batch size 128: total=36328 us, transfer=3028 us, kernel=32609 us
Average latency per batch: 459.85 us, per packet: 3.63 us
Batch size: 128 packets
Total time: 36328 us
Transfer time: 3028 us (8.3%)
Kernel time: 32609 us (89.8%)
Average latency per batch: 459.85 us
Average latency per packet: 3.63 us
Processed 10000 packets: 1448 drops, 1573 forwards, 6979 modifies

--- Testing Batch Size = 256 ---
Batch size 256: total=20240 us, transfer=2966 us, kernel=16889 us
Average latency per batch: 506.00 us, per packet: 2.02 us
Batch size: 256 packets
Total time: 20240 us
Transfer time: 2966 us (14.7%)
Kernel time: 16889 us (83.4%)
Average latency per batch: 506.00 us
Average latency per packet: 2.02 us
Processed 10000 packets: 1448 drops, 1573 forwards, 6979 modifies

--- Testing Batch Size = 512 ---
Batch size 512: total=12977 us, transfer=2924 us, kernel=9799 us
Average latency per batch: 648.85 us, per packet: 1.30 us
Batch size: 512 packets
Total time: 12977 us
Transfer time: 2924 us (22.5%)
Kernel time: 9799 us (75.5%)
Average latency per batch: 648.85 us
Average latency per packet: 1.30 us
Processed 10000 packets: 1448 drops, 1573 forwards, 6979 modifies

--- Testing Batch Size = 1024 ---
Batch size 1024: total=8348 us, transfer=2942 us, kernel=5222 us
Average latency per batch: 834.80 us, per packet: 0.83 us
Batch size: 1024 packets
Total time: 8348 us
Transfer time: 2942 us (35.2%)
Kernel time: 5222 us (62.6%)
Average latency per batch: 834.80 us
Average latency per packet: 0.83 us
Processed 10000 packets: 1448 drops, 1573 forwards, 6979 modifies

=== Optimal Batch Size Found: 1024 ===

=== Running Optimizations with Optimal Batch Size: 1024 ===

=== Stage 2: Pinned Memory Optimization (Batch Size = 1024) ===
Transfer time: 2530 us, Kernel time: 3631 us
Batch size: 1024 packets
Total time: 6268 us
Transfer time: 2530 us (40.4%)
Kernel time: 3631 us (57.9%)
Average latency per packet: 0.00 us
Processed 10000 packets: 9128 drops, 147 forwards, 725 modifies
Pinned memory processing (total): 6268 us

=== Stage 3: Batched Processing with Streams (Batch Size = 1024) ===
Batch size: 1024 packets
Total time: 3242 us
Average latency per batch: 324.20 us
Average latency per packet: 0.32 us
Processed 10000 packets: 1448 drops, 1573 forwards, 6979 modifies
Batched stream processing (total): 3242 us

=== Stage 4: Zero-Copy Memory (Batch Size = 1024) ===
Batch size: 1024 packets
Total time: 61539 us
Average latency per packet: 0.00 us
Processed 10000 packets: 1448 drops, 1573 forwards, 6979 modifies
Zero-copy cudaDeviceSynchronize time: 61529 us (99.98% of total time)
Zero-copy processing (total): 61539 us

=== Stage 5: Real Persistent Kernel (Batch Size = 1024) ===
Starting batch-based persistent kernel processing...
Processing 10000 packets in 10 batches (batch size: 1024)
Launching persistent kernel with 32 blocks x 256 threads...
Persistent kernel launched successfully, now submitting batches...
All work submitted and processed, finalizing...
Persistent kernel completed, copying results...
Final work queue head: 9216, tail: 10000
Batch size: 1024 packets
Total time: 204 us
Average latency per batch: 20.40 us
Average latency per packet: 0.02 us
Processed 10000 packets: 10000 drops, 0 forwards, 0 modifies
Batch-based persistent kernel processing completed successfully
Warning: Packet 0 not completed (status: 0)
Results verification: FAILED (0/10000 packets completed)
Batch-based persistent kernel processing (total): 204 us

=== Stage 6: CUDA Graphs (Batch Size = 1024) ===
Average graph launch time per batch: 282.10 us
Batch size: 1024 packets
Total time: 4534 us
Average latency per packet: 0.00 us
Processed 10000 packets: 0 drops, 10000 forwards, 0 modifies
CUDA Graphs processing (total): 4534 us

=== Overall Performance Comparison ===
CPU Baseline: 4379 us
Basic GPU: 4214 us (1.04x vs CPU)
Pinned Memory: 6268 us (0.70x vs CPU)
Batched Streams: 3242 us (1.35x vs CPU)
Zero-Copy: 61539 us (0.07x vs CPU)
Real Persistent Kernel: 204 us (21.47x vs CPU)
CUDA Graphs: 4534 us (0.97x vs CPU)

=== Optimization Techniques Demonstrated ===
1. Basic processing - baseline
2. Pinned memory - faster host-device transfers
3. Batched streams - overlapping transfers and computation
4. Zero-copy memory - eliminating explicit transfers
5. Real persistent kernel - reducing kernel launch overhead
6. CUDA Graphs - minimizing CPU overhead for launch sequences
