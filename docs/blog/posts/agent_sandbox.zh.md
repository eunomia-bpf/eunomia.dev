---
date: 2026-01-11
---

# 智能体系统架构：隔离、集成与治理的综合调研

基于大语言模型（LLM）的智能体系统——利用LLM自主规划并使用外部工具执行多步骤任务的软件——正在迅速从概念验证演示走向企业部署。这些智能体有望实现编码、IT运维、数据分析等任务的自动化，但在生产环境中部署它们会带来安全性、可靠性和集成方面的新挑战。在过去半年中，社区已经在关键策略上达成共识：为执行不可信操作提供强隔离、为工具集成提供标准化协议，以及使智能体行为与企业策略保持一致的治理框架。本调研对最近的发展（大约2025年下半年）进行了系统回顾，包括智能体沙箱架构、MCP等新兴标准、开源项目、行业倡议和研究进展。我们关注将智能体系统投入生产时遇到的痛点，以及最新解决方案如何解决（或仍未解决）这些需求。

<!-- more -->

## 1. 企业中的智能体系统架构

企业级智能体系统通常由几个层次组成：（i）基于LLM的推理核心（决定采取哪些操作的"智能体"），（ii）调用外部工具或服务的接口（例如通过API、命令行、数据库），以及（iii）智能体的工具操作（如运行代码或shell命令）实际发生的执行环境或运行时。围绕这些的还有用于内存/状态存储的组件、编排（特别是如果多个智能体协同工作）以及用于安全和合规的监控与控制。总体架构挑战在于，这些系统高度动态且开放式：智能体可能会在运行时生成任意代码或工具请求，通常基于不可预测的输入。这需要采用与传统确定性服务不同的软件架构方法。

隔离与安全设计。与有界的微服务不同，AI智能体可能会决定执行未经审查的代码或进行系统更改调用。2025年出现的一个核心架构原则是对智能体的操作进行沙箱隔离——在隔离的环境中运行它们，以保护主机系统和网络。例如，开源的Kubernetes智能体沙箱被引入作为一种新的Kubernetes原语，用于安全运行AI智能体。与其让LLM生成的代码在标准容器中运行（仍可能滥用主机内核或其他Pod），智能体沙箱使用轻量级虚拟机（基于gVisor的用户态内核，可选支持Kata Containers）在智能体代码与集群节点操作系统之间创建安全屏障。这将可能恶意或错误的代码隔离开来，使其无法干扰其他应用程序或主机。沙箱通过名为`Sandbox`的自定义Kubernetes资源（CRD）进行管理，该资源代表一个单一的、有状态的、长期存在的Pod，具有稳定的身份和持久存储。这种设计反映了一种转变，从将智能体工作负载视为短暂的无状态函数转变为将其视为可能随时间保持状态的面向会话的服务。事实上，智能体沙箱支持暂停和恢复虚拟机、在需要网络重新连接时自动恢复它，甚至在沙箱之间共享内存以提高效率等功能。它还提供了模板和池机制——`SandboxTemplate`和`SandboxClaim`——用于管理预热沙箱Pod池。预热至关重要，因为启动一个全新的隔离虚拟机可能很慢；通过保持一个准备就绪的沙箱池，新智能体会话的启动延迟大大降低（Google报告说启动延迟不到一秒，比冷启动沙箱提高了约90%）。在Google的GKE中，这与新的Pod快照功能配对，可以检查点和恢复运行中的沙箱Pod（甚至是GPU工作负载），将启动时间从几分钟缩短到几秒钟，避免空闲资源浪费。简而言之，沙箱架构是专为自主智能体而设计的：它提供了比普通容器更强的隔离，同时支持持久状态和快速弹性，以适应大规模的长期运行的交互式智能体任务。

有状态单例运行时。传统的云应用通常通过在负载均衡器后运行许多无状态实例来扩展，但智能体用例（如AI编码助手或自主调度器）通常表现为具有跨多个工具调用持续存在的内存（如缓存的工具或上下文）的单个专门"工作器"。Kubernetes智能体沙箱明确针对这些单例、有状态的工作负载——不仅适用于AI智能体，还适用于需要稳定身份和磁盘状态的CI/CD构建代理或单节点数据库等。这反映了行业的更广泛认识：智能体应用需要新的运行时原语，可以在会话期间维持状态和身份的连续性（例如，使智能体可以基于先前的工具输出逐步构建，或维护对服务的认证会话）。最近的设计提出了智能体的持久执行——暂停智能体进程、快照其内存或文件系统，然后恢复甚至迁移它的能力。GKE智能体沙箱+ Pod快照组合是这方面的早期现实世界示例，有效地将智能体的环境视为可检查点的虚拟机。我们预计将出现新兴的编排支持，其中智能体可以在空闲时休眠，并在需要时快速唤醒，在响应性和资源高效使用之间取得平衡。

工具接口层。架构的另一个关键部分是智能体如何与外部工具和数据交互。从历史上看，每个AI助手平台都发明了自己的插件系统或API模式（例如OpenAI的插件、LangChain的工具抽象）。这导致了生态系统的碎片化，工具必须为每个智能体框架重写。在2025年，围绕模型上下文协议（MCP）作为AI模型（客户端）和工具或服务（服务器）之间的标准接口已经形成了共识。MCP由Anthropic在2024年底发布，到2025年它已成为"连接AI模型与工具、数据和应用程序的通用标准协议"。从概念上讲，MCP定义了一个简单的基于JSON-RPC的客户端-服务器协议，通过该协议，AI智能体可以发现可用工具并使用参数调用它们，并接收结果/观察。工具可以是任何东西：数据库查询、文件系统操作、网络请求、代码编译——每个都由智能体连接的MCP服务器公开。通用协议的强大之处在于，它将集成问题从M×N（每个模型与每个工具集成）转变为M+N模块化。工具开发人员可以创建一次MCP服务器，任何兼容的智能体（无论是OpenAI的、Anthropic的还是开源项目）都可以使用它。这大大减少了重复工作，使系统更易于维护。GitHub工程师将MCP描述为创建"AI的USB-C"——工具的通用端口。在实践中，MCP连接可以是本地的（通过stdio管道）或远程的（HTTP+SSE流），通常是有状态会话，这与需要维护上下文的智能体工具概念很好地契合（例如，保持打开的数据库连接，或保留cookie的浏览器）。

编排与多智能体工作流。许多实际任务可能对单个智能体来说太复杂，或者可能受益于专门智能体的协作。因此，架构正在扩展以支持智能体相互通信或协调的多智能体系统。一些协议，如智能体到智能体（A2A）消息传递，正在出现以标准化智能体间通信（例如，Google的Agent2Agent协议和Microsoft在其框架中采用A2A）。在多智能体设置中，您可能有一个专门从事规划的智能体、另一个执行代码的智能体、另一个进行验证的智能体等，它们之间传递上下文或子任务。编排框架现在通常支持确定性工作流（其中子任务链是预定义的，类似于业务流程）以及LLM驱动的编排（其中智能体动态决定如何分解和分配任务）。例如，Microsoft的新开源智能体框架明确支持智能体编排（LLM驱动的、创造性的、自适应的）和工作流编排（固定逻辑，用于可靠的可重复性）在一个运行时中。该框架于2025年底发布，将之前的研究原型（如Semantic Kernel的规划器和MSR的AutoGen）整合到企业就绪的SDK中。它强调与企业系统的连接器、开放标准（MCP、A2A、OpenAPI）以及内置的遥测、审批和长期运行的持久性，以满足企业需求。这里的趋势是，智能体被视为软件系统的一等公民组件，对监控、安全和生命周期管理的期望与微服务或人在回路工作流相同。

总结：现代智能体系统的架构正在围绕模块化、分层设计融合。安全的沙箱执行层确保任何生成的代码或命令都在具有受控权限的隔离环境中运行。标准化的工具接口层（MCP和类似协议）将智能体推理与工具的实现解耦，使可重用能力的丰富生态系统成为可能。在这些基础之上，编排机制允许将多个智能体和工具组合成更大的自主工作流，同时为人类和现有DevOps流程提供钩子，以便在需要时进行监督和干预。在接下来的章节中，我们将更深入地探讨企业智能体系统的三个关键方面：（a）沙箱和运行时隔离机制，（b）新兴的工具/插件标准和生态系统，以及（c）组织部署这些系统时最关心的安全、治理和可观测性考虑。

## 2. 智能体的隔离执行环境（沙箱）

运行不受信任或机器生成的代码一直是有风险的——现在的不同之处在于，使用LLM智能体，代码是即时生成和执行的，没有人类审查每个命令。如果智能体被欺骗或其输出不安全，这会打开意外失败甚至恶意利用的大门。因此，沙箱已成为智能体系统的基础要求。这里的沙箱是指将智能体的操作（代码执行、文件系统写入、网络调用等）限制在一个环境中，在该环境中它无法损害其他进程或访问它不应该访问的数据。

